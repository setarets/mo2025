{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-PJzM_fWCB-"
      },
      "source": [
        "# IRIS-Flower-classification\n",
        "\n",
        "Этот проект представляет собой применение машинного обучения с программированием на Python на примере классификации цветов IRIS с использованием машинного обучения с инструментами scikit.\n",
        "Здесь используются алгоритмы, которые представляют собой некоторые типы машинного обучения с учителем и без учителя.\n",
        "\n",
        "[Ирисы Фишера](https://ru.wikipedia.org/wiki/%D0%98%D1%80%D0%B8%D1%81%D1%8B_%D0%A4%D0%B8%D1%88%D0%B5%D1%80%D0%B0) — набор данных для задачи классификации, на примере которого Рональд Фишер в 1936 году продемонстрировал работу разработанного им метода дискриминантного анализа. Иногда его также называют ирисами Андерсона, так как данные были собраны американским ботаником Эдгаром Андерсоном. Этот набор данных стал классическим и часто используется в литературе для иллюстрации работы различных статистических алгоритмов.\n",
        "\n",
        "Ирисы Фишера состоят из данных о 150 экземплярах ириса, по 50 экземпляров из трёх видов — Ирис щетинистый (Iris setosa), Ирис виргинский (Iris virginica) и Ирис разноцветный (Iris versicolor). Для каждого экземпляра измерялись четыре характеристики (в сантиметрах):\n",
        "\n",
        "- Длина наружной доли околоцветника (англ. sepal length);\n",
        "- Ширина наружной доли околоцветника (англ. sepal width);\n",
        "- Длина внутренней доли околоцветника (англ. petal length);\n",
        "- Ширина внутренней доли околоцветника (англ. petal width).\n",
        "\n",
        "На основании этого набора данных требуется построить правило классификации, определяющее вид растения по данным измерений. Это задача многоклассовой классификации, так как имеется три класса — три вида ириса.\n",
        "\n",
        "Один из классов (Iris setosa) линейно-разделим от двух остальных.\n",
        "\n",
        "В качестве задания вам предлагается повторить данные действия по классификации для наборов данных (можно выбрать, что больше понравится, но лучше сделать для всех)\n",
        "- [User Knowledge Modeling Data Set](http://archive.ics.uci.edu/ml/datasets/User+Knowledge+Modeling)\n",
        "- [Blood Transfusion Service Center Data Set](http://archive.ics.uci.edu/ml/datasets/Blood+Transfusion+Service+Center)\n",
        "- [Somerville Happiness Survey Data Set](http://archive.ics.uci.edu/ml/datasets/Somerville+Happiness+Survey)\n",
        "- [Wine Quality Data Set](https://archive.ics.uci.edu/ml/datasets/wine+quality)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXmCE0CDWmKV"
      },
      "outputs": [],
      "source": [
        "# Подключаем библиотеки\n",
        "import pandas as pd # Работа с набором данных\n",
        "import numpy as np # Линейная алгебра\n",
        "# Визуализация данных\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# отключение информационных сообщений\n",
        "from warnings import filterwarnings\n",
        "filterwarnings(action='ignore')\n",
        "\n",
        "# разделение выборки\n",
        "from sklearn.model_selection import train_test_split\n",
        "#метрики\n",
        "from sklearn import metrics\n",
        "#SVC - метод опорных векторов\n",
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0rGanDwXhJ-"
      },
      "outputs": [],
      "source": [
        "# читаем данные\n",
        "url = 'https://raw.githubusercontent.com/yakushinav/omo/main/data/iris.csv'\n",
        "data = pd.read_csv(url)\n",
        "data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6rRqP1yggi2"
      },
      "outputs": [],
      "source": [
        "# Разделим выборку на обучающую и тестовую\n",
        "train, test = train_test_split(data, test_size = 0.4, stratify = data['species'], random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3p1zGpCKhkVn"
      },
      "outputs": [],
      "source": [
        "# Выделим признаки и результат\n",
        "X_train = train[['sepal_length','sepal_width','petal_length','petal_width']]\n",
        "y_train = train.species\n",
        "X_test = test[['sepal_length','sepal_width','petal_length','petal_width']]\n",
        "y_test = test.species\n",
        "\n",
        "fn = ['sepal_length','sepal_width','petal_length','petal_width']\n",
        "cn = data['species'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDcDZts4hkVn"
      },
      "source": [
        "## Метод опорных векторов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCYLg9NQhkVp"
      },
      "source": [
        "Рассмотрим подход к построению функции потерь,\n",
        "основанный на максимизации зазора между классами.\n",
        "Будем рассматривать линейные классификаторы вида\n",
        "$$\n",
        "    a(x) = sign (\\langle w, x \\rangle + b), \\qquad w \\in R^d, b \\in R.\n",
        "$$\n",
        "\n",
        "Будем считать, что существуют такие параметры $w_*$ и $b_*$,\n",
        "что соответствующий им классификатор $a(x)$ не допускает ни одной ошибки\n",
        "на обучающей выборке.\n",
        "В этом случае говорят, что выборка \\emph{линейно разделима}.\n",
        "\n",
        "Пусть задан некоторый классификатор $a(x) = sign (\\langle w, x \\rangle + b)$.\n",
        "Заметим, что если одновременно умножить параметры $w$ и $b$\n",
        "на одну и ту же положительную константу,\n",
        "то классификатор не изменится.\n",
        "Распорядимся этой свободой выбора и отнормируем параметры так, что\n",
        "$$\n",
        "    \\min_{x \\in X} | \\langle w, x \\rangle + b| = 1.\n",
        "$$\n",
        "Можно показать, что расстояние от произвольной точки $x_0 \\in R^d$ до гиперплоскости,\n",
        "определяемой данным классификатором, равно\n",
        "$$\n",
        "    \\rho(x_0, a)\n",
        "    =\n",
        "    \\frac{\n",
        "        |\\langle w, x \\rangle + b|\n",
        "    }{\n",
        "        \\|w\\|\n",
        "    }.\n",
        "$$\n",
        "Тогда расстояние от гиперплоскости до ближайшего объекта обучающей выборки равно\n",
        "$$\n",
        "    \\min_{x \\in X}\n",
        "    \\frac{\n",
        "        |\\langle w, x \\rangle + b|\n",
        "    }{\n",
        "        \\|w\\|\n",
        "    }\n",
        "    =\n",
        "    \\frac{1}{\\|w\\|} \\min_{x \\in X} |\\langle w, x \\rangle + b|\n",
        "    =\n",
        "    \\frac{1}{\\|w\\|}.\n",
        "$$\n",
        "Данная величина также называется \\emph{отступом (margin)}.\n",
        "\n",
        "Таким образом, если классификатор без ошибок разделяет обучающую выборку,\n",
        "то ширина его разделяющей полосы равна $\\frac{2}{\\|w\\|}$.\n",
        "Известно, что максимизация ширины разделяющей полосы приводит\n",
        "к повышению обобщающей способности классификатора \\cite{mohri12foundations}.\n",
        "Вспомним также, что на повышение обобщающей способности направлена и регуляризация,\n",
        "которая штрафует большую норму весов --- а чем больше норма весов,\n",
        "тем меньше ширина разделяющей полосы.\n",
        "\n",
        "Итак, требуется построить классификатор, идеально разделяющий обучающую выборку,\n",
        "и при этом имеющий максимальный отступ.\n",
        "Запишем соответствующую оптимизационную задачу,\n",
        "которая и будет определять метод опорных векторов для линейно разделимой выборки (hard margin support vector machine):\n",
        "$$\n",
        "    \\left\\{\n",
        "        \\begin{aligned}\n",
        "            & \\frac{1}{2} \\|w\\|^2 \\to \\min_{w, b} \\\\\n",
        "            & y_i \\left(\n",
        "                \\langle w, x_i \\rangle + b\n",
        "            \\right) \\geq 1, \\quad i = 1, \\dots, \\ell.\n",
        "        \\end{aligned}\n",
        "    \\right.\n",
        "$$\n",
        "Здесь мы воспользовались тем, что линейный классификатор дает правильный ответ\n",
        "на объекте $x_i$ тогда и только тогда, когда $y_i (\\langle w, x_i \\rangle + b) \\geq 0$.\n",
        "Из условия нормировки следует,\n",
        "что $y_i (\\langle w, x_i \\rangle + b) \\geq 1$.\n",
        "\n",
        "В данной задаче функционал является строго выпуклым, а ограничения линейными,\n",
        "поэтому сама задача является выпуклой и имеет единственное решение.\n",
        "Более того, задача является квадратичной и может быть решена крайне эффективно.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0GpLRYyhDnZ"
      },
      "outputs": [],
      "source": [
        "# Метод опорных векторов, линейная модель\n",
        "linear_svc = SVC(kernel='linear').fit(X_train, y_train)\n",
        "y_pred=linear_svc.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CVvZyrrhkVs"
      },
      "outputs": [],
      "source": [
        "#Выполняем предсказание\n",
        "y_pred=linear_svc.predict(X_test)\n",
        "\n",
        "print('accuracy (точность) классификатора',metrics.accuracy_score(y_pred,y_test))\n",
        "\n",
        "# матрица ошибок\n",
        "print(\"матрица ошибок\")\n",
        "print(metrics.confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GmG70nhhkVu"
      },
      "outputs": [],
      "source": [
        "# Использование построенной модели для предсказания класса\n",
        "new_iris=[1.3, 2.4, 5.6, 3.5]\n",
        "y_new_iris=linear_svc.predict([new_iris])\n",
        "\n",
        "print(y_new_iris)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQvhDCsJhkVu"
      },
      "outputs": [],
      "source": [
        "# Опорные вектора\n",
        "print(linear_svc.support_vectors_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqjJ1_N3hkVv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Классификация для набора данных Somerville Happiness Survey Data Set"
      ],
      "metadata": {
        "id": "ptAp7l98JLzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/setarets/mo2025/refs/heads/main/data/winequality-red.csv'\n",
        "df = pd.read_csv(url, sep=';')\n",
        "print(\"Первые 5 строк DataFrame:\")\n",
        "print(df.head(5))"
      ],
      "metadata": {
        "id": "aFnc9Af0Ld3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('https://raw.githubusercontent.com/setarets/mo2025/refs/heads/main/data/winequality-red.csv')\n",
        "df1 = pd.read_csv(url, sep=';')\n",
        "df2 = pd.read_csv('https://raw.githubusercontent.com/setarets/mo2025/refs/heads/main/data/winequality-white.csv')\n",
        "df2 = pd.read_csv(url, sep=';')\n",
        "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
        "combined_df.to_csv('combined_file.csv', index=False)\n",
        "print(combined_df.head(5))"
      ],
      "metadata": {
        "id": "22oweLnHL3Fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url_red = 'https://raw.githubusercontent.com/setarets/mo2025/refs/heads/main/data/winequality-red.csv'\n",
        "\n",
        "url_white = 'https://raw.githubusercontent.com/setarets/mo2025/refs/heads/main/data/winequality-white.csv'\n",
        "\n",
        "df1 = pd.read_csv(url_red, sep=';')\n",
        "df2 = pd.read_csv(url_white, sep=';')\n",
        "\n",
        "df1 = df1.assign(wine='red')\n",
        "df2 = df2.assign(wine='white')\n",
        "\n",
        "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "combined_df.to_csv('combined_file.csv', index=False)\n",
        "\n",
        "print(combined_df.head(5))\n"
      ],
      "metadata": {
        "id": "KKZusc61Njzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(combined_df.tail(5))"
      ],
      "metadata": {
        "id": "lnfHIc4nNmnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(combined_df, test_size = 0.4, stratify = combined_df['quality'], random_state = 42)"
      ],
      "metadata": {
        "id": "Qd4LPGfbNxCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(combined_df.columns.tolist())"
      ],
      "metadata": {
        "id": "S_c_xSh5OCgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']]\n",
        "y_train = train.quality\n",
        "X_test = test[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']]\n",
        "y_test = test.quality\n",
        "\n",
        "fn = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n",
        "cn = combined_df['quality'].unique()"
      ],
      "metadata": {
        "id": "ayLMrtY8N8ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_svc = SVC(kernel='linear').fit(X_train, y_train)\n",
        "y_pred=linear_svc.predict(X_test)"
      ],
      "metadata": {
        "id": "NiViSfiHOdab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=linear_svc.predict(X_test)\n",
        "\n",
        "print('accuracy (точность) классификатора',metrics.accuracy_score(y_pred,y_test))\n",
        "\n",
        "print(\"матрица ошибок\")\n",
        "print(metrics.confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "cDU2LPmuOemH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_quality = [7.4, 0.7, 0, 1.9, 0.076, 11, 34, 0.9978, 3.51, 0.56, 9.4, 12.0]\n",
        "y_new_quality=linear_svc.predict([new_quality])\n",
        "print(y_new_quality)"
      ],
      "metadata": {
        "id": "tlPxCDmwOmYD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}